{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78a3a427",
   "metadata": {},
   "source": [
    "# 07. Gradient and Autograd Deep Dive\n",
    "\n",
    "Understanding how PyTorch computes gradients automatically is crucial for deep learning success. This notebook will take you deep into PyTorch's autograd system and help you understand:\n",
    "\n",
    "- How automatic differentiation works\n",
    "- The computational graph concept\n",
    "- Forward and backward propagation in detail\n",
    "- Gradient accumulation and manipulation\n",
    "- Common autograd pitfalls and solutions\n",
    "- Custom gradient functions\n",
    "\n",
    "**Why is this important?**\n",
    "\n",
    "Understanding autograd helps you:\n",
    "\n",
    "- Debug gradient-related issues effectively\n",
    "- Optimize training performance\n",
    "- Implement custom training procedures\n",
    "- Understand what happens \"under the hood\" in PyTorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e8767e",
   "metadata": {},
   "source": [
    "## What is Automatic Differentiation?\n",
    "\n",
    "Automatic differentiation (autodiff) is a technique for computing derivatives of functions defined by computer programs. Unlike symbolic or numerical differentiation, autodiff can compute exact derivatives efficiently.\n",
    "\n",
    "### Types of Autodiff:\n",
    "\n",
    "1. **Forward Mode**: Computes derivatives along with the forward pass\n",
    "2. **Reverse Mode**: Computes derivatives in a backward pass (used by PyTorch)\n",
    "\n",
    "### Why Reverse Mode for Deep Learning?\n",
    "\n",
    "Reverse mode autodiff is particularly efficient for functions with many inputs and few outputs (like neural networks with many parameters and one loss output).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "837f452f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchviz import make_dot  # For visualizing computational graphs\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a9ff92",
   "metadata": {},
   "source": [
    "## The Computational Graph\n",
    "\n",
    "PyTorch builds a computational graph dynamically as you perform operations. Each tensor operation creates a node in this graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e88ee93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 2.0\n",
      "x.requires_grad: True\n",
      "y = 11.0\n",
      "y.grad_fn: <AddBackward0 object at 0x107afc370>\n",
      "\n",
      "Computational graph:\n",
      "x -> None\n",
      "y -> <AddBackward0 object at 0x107bf5a50>\n"
     ]
    }
   ],
   "source": [
    "# Simple example: y = x^2 + 3x + 1\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "print(f\"x = {x}\")\n",
    "print(f\"x.requires_grad: {x.requires_grad}\")\n",
    "\n",
    "# Perform operations\n",
    "y = x**2 + 3 * x + 1\n",
    "print(f\"y = {y}\")\n",
    "print(f\"y.grad_fn: {y.grad_fn}\")\n",
    "\n",
    "# The computational graph is built!\n",
    "# Let's visualize it\n",
    "print(f\"\\nComputational graph:\")\n",
    "print(f\"x -> {x.grad_fn}\")\n",
    "print(f\"y -> {y.grad_fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a313da6b",
   "metadata": {},
   "source": [
    "## Computing Gradients with .backward()\n",
    "\n",
    "The `.backward()` method computes gradients by traversing the computational graph in reverse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95993ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx = 7.0\n",
      "Manual calculation: 7.0\n",
      "PyTorch autograd: 7.0\n"
     ]
    }
   ],
   "source": [
    "# Compute gradients\n",
    "y.backward()\n",
    "\n",
    "print(f\"dy/dx = {x.grad}\")\n",
    "\n",
    "# Let's verify this manually\n",
    "# y = x^2 + 3x + 1\n",
    "# dy/dx = 2x + 3\n",
    "# At x = 2: dy/dx = 2(2) + 3 = 7\n",
    "manual_gradient = 2 * x.data + 3\n",
    "print(f\"Manual calculation: {manual_gradient}\")\n",
    "print(f\"PyTorch autograd: {x.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca98cfe",
   "metadata": {},
   "source": [
    "## Gradient Accumulation\n",
    "\n",
    "By default, gradients accumulate in the `.grad` attribute. This is useful for techniques like gradient accumulation for large batch sizes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2f73c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: x.grad = 4.0\n",
      "Iteration 2: x.grad = 9.0\n",
      "Iteration 3: x.grad = 15.0\n",
      "After reset: x.grad = None\n"
     ]
    }
   ],
   "source": [
    "# Reset gradients\n",
    "x.grad = None\n",
    "\n",
    "# Compute gradients multiple times\n",
    "for i in range(3):\n",
    "    y = x**2 + i * x\n",
    "    y.backward()\n",
    "    print(f\"Iteration {i+1}: x.grad = {x.grad}\")\n",
    "\n",
    "# Gradients are accumulated!\n",
    "# To clear gradients, use zero_grad() or set to None\n",
    "x.grad = None\n",
    "print(f\"After reset: x.grad = {x.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0242856",
   "metadata": {},
   "source": [
    "## Working with Tensors and Gradients\n",
    "\n",
    "Let's explore how gradients work with multi-dimensional tensors and multiple variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cf347a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z = 46.0\n",
      "dz/dx = tensor([ 6.,  9., 12.])\n",
      "dz/dy = tensor([1., 2., 3.])\n",
      "Manual dz/dx: tensor([ 6.,  9., 12.])\n"
     ]
    }
   ],
   "source": [
    "# Multiple variables\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "y = torch.tensor([4.0, 5.0, 6.0], requires_grad=True)\n",
    "\n",
    "# Compute a scalar loss\n",
    "z = torch.sum(x * y + x**2)\n",
    "print(f\"z = {z}\")\n",
    "\n",
    "# Compute gradients\n",
    "z.backward()\n",
    "\n",
    "print(f\"dz/dx = {x.grad}\")\n",
    "print(f\"dz/dy = {y.grad}\")\n",
    "\n",
    "# Manual verification:\n",
    "# z = sum(x*y + x^2) = sum([1*4 + 1^2, 2*5 + 2^2, 3*6 + 3^2])\n",
    "# z = sum([5, 14, 27]) = 46\n",
    "# dz/dx = [y[0] + 2*x[0], y[1] + 2*x[1], y[2] + 2*x[2]]\n",
    "# dz/dx = [4 + 2*1, 5 + 2*2, 6 + 2*3] = [6, 9, 12]\n",
    "print(f\"Manual dz/dx: {y.data + 2*x.data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6a5a44",
   "metadata": {},
   "source": [
    "## Understanding requires_grad\n",
    "\n",
    "The `requires_grad` parameter controls whether PyTorch should track operations for gradient computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8914f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.requires_grad: True\n",
      "b.requires_grad: False\n",
      "c.requires_grad: False\n",
      "(a * b).requires_grad: True\n",
      "(b * c).requires_grad: False\n"
     ]
    }
   ],
   "source": [
    "# Tensors with and without gradient tracking\n",
    "a = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(3.0, requires_grad=False)\n",
    "c = torch.tensor(4.0)  # requires_grad=False by default\n",
    "\n",
    "print(f\"a.requires_grad: {a.requires_grad}\")\n",
    "print(f\"b.requires_grad: {b.requires_grad}\")\n",
    "print(f\"c.requires_grad: {c.requires_grad}\")\n",
    "\n",
    "# Operations inherit gradient requirements\n",
    "result1 = a * b  # Result requires grad because a does\n",
    "result2 = b * c  # Result doesn't require grad because neither b nor c do\n",
    "\n",
    "print(f\"(a * b).requires_grad: {result1.requires_grad}\")\n",
    "print(f\"(b * c).requires_grad: {result2.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64f6eed",
   "metadata": {},
   "source": [
    "## Detaching from the Computational Graph\n",
    "\n",
    "Sometimes you want to stop gradient computation for certain operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4d976b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1.requires_grad: True\n",
      "y2.requires_grad: False\n",
      "y3.requires_grad: False\n",
      "x.data_ptr() == x.detach().data_ptr(): True\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "# Normal computation\n",
    "y1 = x**2\n",
    "print(f\"y1.requires_grad: {y1.requires_grad}\")\n",
    "\n",
    "# Detached computation\n",
    "y2 = x.detach() ** 2\n",
    "print(f\"y2.requires_grad: {y2.requires_grad}\")\n",
    "\n",
    "# Using torch.inference_mode() (preferred over torch.no_grad())\n",
    "with torch.inference_mode():\n",
    "    y3 = x**2\n",
    "    print(f\"y3.requires_grad: {y3.requires_grad}\")\n",
    "\n",
    "# The detached tensor shares storage but not gradient history\n",
    "print(f\"x.data_ptr() == x.detach().data_ptr(): {x.data_ptr() == x.detach().data_ptr()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7887c0",
   "metadata": {},
   "source": [
    "## Neural Network Example: Manual Implementation\n",
    "\n",
    "Let's implement a simple neural network manually to see autograd in action.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c27c1419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.1897\n",
      "Epoch 20, Loss: 0.7134\n",
      "Epoch 40, Loss: 0.5733\n",
      "Epoch 60, Loss: 0.4824\n",
      "Epoch 80, Loss: 0.4119\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a simple dataset\n",
    "torch.manual_seed(42)\n",
    "X = torch.randn(100, 2)  # 100 samples, 2 features\n",
    "y = (X[:, 0] + X[:, 1] > 0).float().unsqueeze(1)  # Simple classification\n",
    "\n",
    "# Manual neural network parameters\n",
    "W1 = torch.randn(2, 5, requires_grad=True)  # Input to hidden\n",
    "b1 = torch.zeros(5, requires_grad=True)  # Hidden bias\n",
    "W2 = torch.randn(5, 1, requires_grad=True)  # Hidden to output\n",
    "b2 = torch.zeros(1, requires_grad=True)  # Output bias\n",
    "\n",
    "\n",
    "def forward(X):\n",
    "    \"\"\"Forward pass through the network\"\"\"\n",
    "    h = torch.relu(X @ W1 + b1)  # Hidden layer\n",
    "    out = torch.sigmoid(h @ W2 + b2)  # Output layer\n",
    "    return out\n",
    "\n",
    "\n",
    "def compute_loss(predictions, targets):\n",
    "    \"\"\"Binary cross-entropy loss\"\"\"\n",
    "    return -torch.mean(\n",
    "        targets * torch.log(predictions + 1e-8)\n",
    "        + (1 - targets) * torch.log(1 - predictions + 1e-8)\n",
    "    )\n",
    "\n",
    "\n",
    "# Training loop\n",
    "learning_rate = 0.1\n",
    "losses = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    # Forward pass\n",
    "    predictions = forward(X)\n",
    "    loss = compute_loss(predictions, y)\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters manually\n",
    "    with torch.inference_mode():\n",
    "        W1 -= learning_rate * W1.grad\n",
    "        b1 -= learning_rate * b1.grad\n",
    "        W2 -= learning_rate * W2.grad\n",
    "        b2 -= learning_rate * b2.grad\n",
    "\n",
    "    # Clear gradients\n",
    "    W1.grad = None\n",
    "    b1.grad = None\n",
    "    W2.grad = None\n",
    "    b2.grad = None\n",
    "\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Plot the loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(losses)\n",
    "plt.title(\"Training Loss Over Time\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ad3a74",
   "metadata": {},
   "source": [
    "## Gradient Accumulation for Large Batches\n",
    "\n",
    "When memory is limited, you can simulate larger batch sizes by accumulating gradients across multiple smaller batches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f41e3dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 4.9993\n",
      "Epoch 2, Average Loss: 4.8793\n",
      "Epoch 3, Average Loss: 4.7709\n",
      "Epoch 4, Average Loss: 4.6728\n",
      "Epoch 5, Average Loss: 4.5839\n"
     ]
    }
   ],
   "source": [
    "# Simulate gradient accumulation\n",
    "model = nn.Linear(10, 1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Create some dummy data\n",
    "X = torch.randn(100, 10)\n",
    "y = torch.randn(100, 1)\n",
    "\n",
    "accumulation_steps = 4\n",
    "batch_size = 8\n",
    "\n",
    "for epoch in range(5):\n",
    "    total_loss = 0\n",
    "    optimizer.zero_grad()  # Clear gradients at the start of each epoch\n",
    "\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        # Get mini-batch\n",
    "        batch_X = X[i : i + batch_size]\n",
    "        batch_y = y[i : i + batch_size]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        # Scale loss by accumulation steps\n",
    "        loss = loss / accumulation_steps\n",
    "\n",
    "        # Backward pass (accumulates gradients)\n",
    "        loss.backward()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Update parameters every accumulation_steps\n",
    "        if (i // batch_size + 1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Average Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597aa8b9",
   "metadata": {},
   "source": [
    "## Custom Autograd Functions\n",
    "\n",
    "For advanced use cases, you can define custom autograd functions with custom forward and backward passes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e53e2e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 9.0\n",
      "dy/dx = 6.0\n"
     ]
    }
   ],
   "source": [
    "class SquareFunction(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Custom autograd function that squares its input.\n",
    "    This example shows how to define custom forward and backward passes.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        Forward pass: compute the output\n",
    "        ctx: context object to save information for backward pass\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)  # Save input for backward pass\n",
    "        return input * input\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        Backward pass: compute gradient with respect to input\n",
    "        grad_output: gradient flowing back from the next layer\n",
    "        \"\"\"\n",
    "        (input,) = ctx.saved_tensors  # Retrieve saved input\n",
    "        grad_input = grad_output * 2 * input  # d/dx(x^2) = 2x\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "# Use the custom function\n",
    "square = SquareFunction.apply\n",
    "\n",
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "y = square(x)\n",
    "print(f\"y = {y}\")\n",
    "\n",
    "y.backward()\n",
    "print(f\"dy/dx = {x.grad}\")  # Should be 2*3 = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4974e9ee",
   "metadata": {},
   "source": [
    "## Common Autograd Pitfalls and Solutions\n",
    "\n",
    "### 1. In-place Operations\n",
    "\n",
    "In-place operations can cause issues with autograd because they modify tensors that might be needed for gradient computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39252904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-in-place operation successful\n",
      "In-place on detached tensor successful\n"
     ]
    }
   ],
   "source": [
    "# Problematic in-place operation\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = x**2\n",
    "\n",
    "# This would cause an error during backward pass\n",
    "# x.add_(1)  # In-place addition - DON'T DO THIS!\n",
    "\n",
    "# Solution: Use non-in-place operations\n",
    "x_new = x + 1\n",
    "print(\"Non-in-place operation successful\")\n",
    "\n",
    "# Or use .detach() if you really need in-place\n",
    "x_detached = x.detach()\n",
    "x_detached.add_(1)\n",
    "print(\"In-place on detached tensor successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b5c1fc",
   "metadata": {},
   "source": [
    "### 2. Forgetting to Zero Gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a7a4311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without zeroing gradients:\n",
      "Iteration 1: x.grad = 4.0\n",
      "Iteration 2: x.grad = 8.0\n",
      "Iteration 3: x.grad = 12.0\n",
      "\n",
      "With proper gradient zeroing:\n",
      "Iteration 1: x.grad = 4.0\n",
      "Iteration 2: x.grad = 4.0\n",
      "Iteration 3: x.grad = 4.0\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate the importance of zeroing gradients\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "print(\"Without zeroing gradients:\")\n",
    "for i in range(3):\n",
    "    y = x**2\n",
    "    y.backward()\n",
    "    print(f\"Iteration {i+1}: x.grad = {x.grad}\")\n",
    "\n",
    "print(\"\\nWith proper gradient zeroing:\")\n",
    "for i in range(3):\n",
    "    if x.grad is not None:\n",
    "        x.grad.zero_()  # or x.grad = None\n",
    "    y = x**2\n",
    "    y.backward()\n",
    "    print(f\"Iteration {i+1}: x.grad = {x.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b77c16",
   "metadata": {},
   "source": [
    "## Gradient Checking\n",
    "\n",
    "It's good practice to verify your gradients numerically, especially when implementing custom functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aae4b50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical gradient: tensor([4., 6.])\n",
      "Numerical gradient:  tensor([4.0054, 6.0081])\n",
      "Difference: tensor([0.0054, 0.0081])\n"
     ]
    }
   ],
   "source": [
    "def numerical_gradient(f, x, h=1e-5):\n",
    "    \"\"\"\n",
    "    Compute numerical gradient using finite differences\n",
    "    \"\"\"\n",
    "    grad = torch.zeros_like(x)\n",
    "\n",
    "    for i in range(x.numel()):\n",
    "        # Create copies for perturbation\n",
    "        x_plus = x.clone()\n",
    "        x_minus = x.clone()\n",
    "\n",
    "        # Perturb\n",
    "        x_plus.view(-1)[i] += h\n",
    "        x_minus.view(-1)[i] -= h\n",
    "\n",
    "        # Compute finite difference\n",
    "        grad.view(-1)[i] = (f(x_plus) - f(x_minus)) / (2 * h)\n",
    "\n",
    "    return grad\n",
    "\n",
    "\n",
    "# Test function: f(x) = x^2 + 2*x + 1\n",
    "def test_function(x):\n",
    "    return (x**2 + 2 * x + 1).sum()\n",
    "\n",
    "\n",
    "# Compare numerical and analytical gradients\n",
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "\n",
    "# Analytical gradient\n",
    "y = test_function(x)\n",
    "y.backward()\n",
    "analytical_grad = x.grad.clone()\n",
    "\n",
    "# Numerical gradient\n",
    "x.grad = None\n",
    "numerical_grad = numerical_gradient(test_function, x.detach())\n",
    "\n",
    "print(f\"Analytical gradient: {analytical_grad}\")\n",
    "print(f\"Numerical gradient:  {numerical_grad}\")\n",
    "print(f\"Difference: {torch.abs(analytical_grad - numerical_grad)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe8b1b3",
   "metadata": {},
   "source": [
    "## Performance Considerations\n",
    "\n",
    "Understanding autograd performance can help you write more efficient code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2c1acbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With gradients: 0.0537s\n",
      "Without gradients: 0.0089s\n",
      "Overhead: 501.1%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Large tensor operations\n",
    "x = torch.randn(1000, 1000, requires_grad=True)\n",
    "\n",
    "# Time with gradient computation\n",
    "start_time = time.time()\n",
    "for _ in range(10):\n",
    "    y = torch.sum(x**2)\n",
    "    y.backward()\n",
    "    x.grad = None\n",
    "grad_time = time.time() - start_time\n",
    "\n",
    "# Time without gradient computation\n",
    "with torch.inference_mode():\n",
    "    start_time = time.time()\n",
    "    for _ in range(10):\n",
    "        y = torch.sum(x**2)\n",
    "    no_grad_time = time.time() - start_time\n",
    "\n",
    "print(f\"With gradients: {grad_time:.4f}s\")\n",
    "print(f\"Without gradients: {no_grad_time:.4f}s\")\n",
    "print(f\"Overhead: {((grad_time - no_grad_time) / no_grad_time * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac429a54",
   "metadata": {},
   "source": [
    "## Best Practices for Autograd\n",
    "\n",
    "### 1. Use `torch.inference_mode()` for inference\n",
    "\n",
    "```python\n",
    "# Preferred for inference\n",
    "with torch.inference_mode():\n",
    "    predictions = model(data)\n",
    "```\n",
    "\n",
    "### 2. Clear gradients properly\n",
    "\n",
    "```python\n",
    "# Method 1: Set to None (more memory efficient)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Method 2: Manual zeroing\n",
    "for param in model.parameters():\n",
    "    param.grad = None\n",
    "```\n",
    "\n",
    "### 3. Avoid unnecessary gradient computation\n",
    "\n",
    "```python\n",
    "# Only set requires_grad=True for parameters you want to optimize\n",
    "model_params = [p for p in model.parameters() if p.requires_grad]\n",
    "```\n",
    "\n",
    "### 4. Use gradient clipping for stable training\n",
    "\n",
    "```python\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ae5fd3",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've covered:\n",
    "\n",
    "1. **How autograd works**: Reverse-mode automatic differentiation\n",
    "2. **Computational graphs**: How PyTorch tracks operations\n",
    "3. **Gradient computation**: Using `.backward()` and understanding gradient flow\n",
    "4. **Gradient manipulation**: Accumulation, detaching, and custom functions\n",
    "5. **Common pitfalls**: In-place operations, gradient zeroing, and scalar outputs\n",
    "6. **Performance considerations**: When to use `torch.inference_mode()`\n",
    "7. **Best practices**: Writing efficient and correct gradient-based code\n",
    "\n",
    "Understanding autograd deeply will help you:\n",
    "\n",
    "- Debug gradient-related issues effectively\n",
    "- Implement custom training procedures\n",
    "- Optimize model performance\n",
    "- Build more complex architectures with confidence\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Practice implementing custom autograd functions\n",
    "- Experiment with gradient accumulation strategies\n",
    "- Try implementing advanced optimizers from scratch\n",
    "- Explore gradient-based meta-learning techniques\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ae3d170",
   "metadata": {},
   "source": [
    "# 02. Neural Networks\n",
    "\n",
    "In this section, we will learn about **neural networks** and focus more on their architecture and training process.\n",
    "\n",
    "In the next notebook, [03. Neural Networks in PyTorch](03_neural_networks_in_pytorch.ipynb), we will implement a neural network using PyTorch.\n",
    "\n",
    "Let's say you want to predict if you will pass an exam `(1)` or not `(0)`. You have the following data:\n",
    "\n",
    "- Hours studied (x1)\n",
    "- How smart you are (x2)\n",
    "- Previous knowledge (x3)\n",
    "- Name (x4)\n",
    "\n",
    "This means that our neural network will take four inputs: `x1`, `x2`, `x3`, and `x4`. The output will be a single value, which is either `0` or `1` (pass or fail).\n",
    "\n",
    "As you can probably guess, not all of these features are useful for predicting the outcome. For example, your name is not a good predictor of whether you will pass the exam or not.\n",
    "\n",
    "Let's walk through the steps of how the neural network will work.\n",
    "\n",
    "> Note: I will include videos and articles that explain the concepts in more detail in the last section of this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514418b7",
   "metadata": {},
   "source": [
    "## Neural Network Structure\n",
    "\n",
    "A neural network is made up of layers of neurons. Each neuron takes inputs, applies a transformation, and produces an output. The output of one layer becomes the input to the next layer.\n",
    "\n",
    "To take our previous example, we can represent the neural network structure as follows:\n",
    "\n",
    "<img src=\"../09_images/01-neural_network_structure.png\" alt=\"Neural Network Structure\" width=\"800\">\n",
    "\n",
    "The neural network has:\n",
    "\n",
    "- **Input Layer**: The first layer that takes the inputs `x1`, `x2`, `x3`, and `x4`.\n",
    "- **Hidden Layer**: The layer that processes the inputs and applies transformations. In this case, we have one neuron in the hidden layer, but we could have more neurons and more layers for a more complex model.\n",
    "- **Output Layer**: The final layer that produces the output. In this case, we have one output neuron that gives the final prediction.\n",
    "\n",
    "Now let's investigate how the neural network works step by step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493c9802",
   "metadata": {},
   "source": [
    "### Step 1: Initializating Weights and Biases\n",
    "\n",
    "In a neural network, we have **[weights](https://www.geeksforgeeks.org/deep-learning/the-role-of-weights-and-bias-in-neural-networks/)** and **[biases](https://www.turing.com/kb/necessity-of-bias-in-neural-networks)**. Weights are the parameters that the model learns during training, and biases are added to the weighted sum of inputs to help the model fit the data better.\n",
    "\n",
    "The weights and biases are initialized randomly at the beginning of the training process. For our example, we will have four weights (one for each input) and one bias.\n",
    "\n",
    "The weights measure the importance of each input feature, while the bias allows the model to shift the output up or down. As mentioned earlier, not all features are useful for predicting the outcome, so the weights will adjust accordingly during training.\n",
    "\n",
    "For example, if the weight for `x4` (name) is close to zero, it means that the name is not a useful feature for predicting the outcome. The model will learn to ignore it.\n",
    "\n",
    "### Step 2: Forward Pass\n",
    "\n",
    "In the forward pass, the inputs are multiplied by their corresponding weights, and the bias is added to the weighted sum. This is done for each neuron in the hidden layer.\n",
    "\n",
    "The output of the hidden layer is then passed through an activation function, which introduces non-linearity into the model. This allows the neural network to learn complex patterns in the data (this will be explained in more detail in a later section).\n",
    "\n",
    "<img src=\"../09_images/01-weight_initialization.png\" alt=\"Initializing Weights and Biases\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8921a0cd",
   "metadata": {},
   "source": [
    "### Step 3: Calculating Loss\n",
    "\n",
    "After the forward pass, we need to calculate the loss, which measures how well the model's predictions match the actual labels. The loss function quantifies the difference between the predicted output and the true output.\n",
    "\n",
    "### Step 4: Backward Pass\n",
    "\n",
    "In the backward pass, we calculate the gradients of the loss with respect to the weights and biases. This is done using **backpropagation**, which is a method for calculating the gradients efficiently.\n",
    "\n",
    "The gradients tell us how much the loss will change if we adjust the weights and biases. We use these gradients to update the weights and biases in the direction that reduces the loss.\n",
    "\n",
    "### Step 5: Updating Weights and Biases\n",
    "\n",
    "After calculating the gradients, we update the weights and biases using an optimization algorithm. The weights and biases are adjusted in the direction that minimizes the loss.\n",
    "This process is repeated for multiple iterations (epochs) until the model converges and the loss reaches an acceptable level.\n",
    "\n",
    "To summarize, the steps of a neural network are:\n",
    "\n",
    "1. Initialize weights and biases randomly.\n",
    "2. Perform a forward pass to calculate the output.\n",
    "3. Calculate the loss.\n",
    "4. Perform a backward pass to calculate gradients.\n",
    "5. Update weights and biases using the gradients.\n",
    "6. Repeat steps 2-5 for multiple epochs until convergence.\n",
    "\n",
    "<img src=\"../09_images/01-neural_network_complete.png\" alt=\"Neural Network Steps\" width=\"1000\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e0b2b3",
   "metadata": {},
   "source": [
    "## Extra Reading\n",
    "\n",
    "For a good overview of neural networks, I would highly recommend going through those 4 videos:\n",
    "\n",
    "1. [But what is a Neural Network?](https://www.youtube.com/watch?v=aircAruvnKk)\n",
    "2. [Gradient Descent, How Neural Networks Learn](https://www.youtube.com/watch?v=IHZwWFHWa-w&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=2U)\n",
    "3. [Backpropagation, Intuitively](https://www.youtube.com/watch?v=Ilg3gGewQ5U)\n",
    "4. [Backpropagation, Calculus](https://www.youtube.com/watch?v=tIeHLnjs5U8)\n",
    "\n",
    "For loss functions, I would recommend reading the following articles:\n",
    "\n",
    "- [Loss Functions Explained](https://medium.com/deep-learning-demystified/loss-functions-explained-3098e8ff2b27)\n",
    "- [PyTorch Loss Functions: The Ultimate Guide](https://neptune.ai/blog/pytorch-loss-functions)\n",
    "- [PyTorch Loss Functions](https://www.digitalocean.com/community/tutorials/pytorch-loss-functions)\n",
    "\n",
    "For gradient descent, I would recommend reading the following articles:\n",
    "\n",
    "- [Gradient Descent Explained](https://medium.com/@abhaysingh71711/gradient-descent-explained-the-engine-behind-ai-training-2d8ef6ecad6f)\n",
    "- [Gradient Descent Algorithm in Machine Learning](https://www.geeksforgeeks.org/gradient-descent-algorithm-and-its-variants/)\n",
    "- [Wikipedia: Gradient Descent](https://en.wikipedia.org/wiki/Gradient_descent)\n",
    "\n",
    "For backpropagation, I would recommend reading the following articles:\n",
    "\n",
    "- [Wikipedia: Backpropagation](https://en.wikipedia.org/wiki/Backpropagation)\n",
    "- [Backpropagation in Neural Networks](https://www.geeksforgeeks.org/machine-learning/backpropagation-in-neural-network/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080d8493",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
